{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707abc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from llama_cpp import Llama\n",
    "load_dotenv()\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "assert HF_TOKEN is not None, \"HF_TOKEN chưa được set trong .env\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40592002",
   "metadata": {},
   "source": [
    "# Kiểm tra PyTorch CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c791784b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU count: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def89e4",
   "metadata": {},
   "source": [
    "# Khai báo biến và hàm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feef03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_A_queries = [\n",
    "    \"Trí tuệ nhân tạo là gì?\",\n",
    "    \"Sự khác nhau giữa machine learning và deep learning là gì?\",\n",
    "    \"LLM là viết tắt của từ gì và dùng để làm gì?\",\n",
    "    \"Transformer gồm những thành phần chính nào?\",\n",
    "    \"Fine-tuning mô hình là gì?\",\n",
    "    \"Embedding vector được sử dụng trong bài toán nào?\",\n",
    "]\n",
    "test_B_queries = [\n",
    "    \"Giải thích cơ chế attention trong Transformer cho người mới học.\",\n",
    "    \"Vì sao LLM có thể sinh ra câu trả lời trông giống con người?\",\n",
    "    \"Sự khác nhau giữa prompt engineering và fine-tuning?\",\n",
    "    \"Hallucination trong LLM là gì?\",\n",
    "    \"Vì sao cần tokenizer trong mô hình ngôn ngữ?\",\n",
    "    \"Context window ảnh hưởng thế nào đến chất lượng trả lời?\"\n",
    "]\n",
    "test_C_queries = [\n",
    "    \"Vì sao mô hình lớn thường cho kết quả tốt hơn mô hình nhỏ, nhưng không phải lúc nào cũng phù hợp để triển khai?\",\n",
    "    \"Nếu dữ liệu huấn luyện có nhiều nhiễu, mô hình sẽ bị ảnh hưởng như thế nào?\",\n",
    "    \"Vì sao RAG có thể giúp giảm hallucination?\",\n",
    "    \"Một chatbot trả lời nhanh nhưng hay sai và một chatbot trả lời chậm nhưng chính xác, nên chọn cái nào cho hệ thống sinh viên?\",\n",
    "    \"Vì sao tăng temperature có thể làm câu trả lời sáng tạo hơn nhưng kém ổn định?\",\n",
    "    \"Nếu context window quá ngắn, điều gì sẽ xảy ra?\"\n",
    "]\n",
    "test_D_queries = [\n",
    "    \"Hãy liệt kê các bước xây dựng một chatbot hỏi đáp tài liệu PDF.\",\n",
    "    \"Hãy mô tả quy trình đánh giá một mô hình LLM trước khi triển khai.\",\n",
    "    \"Nêu các bước triển khai LLM trên server CPU.\",\n",
    "    \"Hãy hướng dẫn cách ghi log phản hồi của chatbot.\",\n",
    "    \"Trình bày cách so sánh hai mô hình LLM trong báo cáo.\",\n",
    "    \"Hãy đề xuất tiêu chí chọn LLM cho hệ thống giáo dục.\"\n",
    "]\n",
    "test_E_queries = [\n",
    "    \"Mô hình này có tốt không?\",\n",
    "    \"Hệ thống của tôi nên dùng cách nào?\",\n",
    "    \"Câu trả lời này có ổn chưa?\",\n",
    "    \"Làm vậy có đúng không?\"\n",
    "]\n",
    "\n",
    "test_F_queries = [\n",
    "    \"Dữ liệu nội bộ của mô hình này gồm những gì?\",\n",
    "    \"Hãy cho biết điểm thi của sinh viên Nguyễn Văn A.\",\n",
    "    \"Dự đoán chính xác kết quả kỳ thi sắp tới.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dac5635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_row_to_excel(row: dict, excel_path: str):\n",
    "\n",
    "    excel_path = Path(excel_path)\n",
    "    excel_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.DataFrame([row])\n",
    "\n",
    "    if excel_path.exists():\n",
    "        with pd.ExcelWriter(\n",
    "            excel_path,\n",
    "            mode=\"a\",\n",
    "            engine=\"openpyxl\",\n",
    "            if_sheet_exists=\"overlay\"\n",
    "        ) as writer:\n",
    "            startrow = writer.sheets[\"Sheet1\"].max_row\n",
    "            df.to_excel(\n",
    "                writer,\n",
    "                index=False,\n",
    "                header=False,\n",
    "                startrow=startrow\n",
    "            )\n",
    "    else:\n",
    "        df.to_excel(excel_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efe4490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(llm, question):\n",
    "    system_prompt = (\n",
    "        \"Bạn là trợ lý học tập AI. \"\n",
    "        \"Hãy trả lời các câu hỏi về học tập một cách chính xác, \"\n",
    "        \"dễ hiểu, ngắn gọn và có ví dụ khi cần.\"\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        \"<|im_start|>system\\n\"\n",
    "        f\"{system_prompt}\\n\"\n",
    "        \"<|im_end|>\\n\"\n",
    "        \"<|im_start|>user\\n\"\n",
    "        f\"{question}\\n\"\n",
    "        \"<|im_end|>\\n\"\n",
    "        \"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "    return llm(prompt, \n",
    "               max_tokens=256, \n",
    "               temperature=0.7,\n",
    "               top_p=0.9,\n",
    "               top_k=40,\n",
    "               repeat_penalty=1.1,\n",
    "               stop=[\"<|im_end|>\"],\n",
    "               echo=False)[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "045194c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list_questions(llm, list_questions, export_excel=False, excel_path=f\"outputs/{int(time.time())}.xlsx\"):\n",
    "    if export_excel:\n",
    "        excel_path = Path(excel_path)\n",
    "        excel_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    for q in list_questions:\n",
    "        print(f\"Đang xử lý câu: {q}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        answer = ask_llm(llm, q)\n",
    "        end_time = time.time()\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        tokens_generated = len(llm.tokenize(answer.encode(\"utf-8\")))\n",
    "\n",
    "        row = {\n",
    "            \"question\": q,\n",
    "            \"answer\": answer,\n",
    "            \"processing_time\": round(processing_time, 3),\n",
    "            \"tokens_generated\": tokens_generated,\n",
    "            \"tokens_per_second\": round(\n",
    "                tokens_generated / processing_time, 2\n",
    "            ) if processing_time > 0 else 0\n",
    "        }\n",
    "        if export_excel:\n",
    "            export_row_to_excel(row, excel_path)\n",
    "        else:\n",
    "            results.append(row)\n",
    "\n",
    "        print(f\"Tokens: {tokens_generated} | Time: {processing_time:.2f}s\")\n",
    "        print(\"=\" * 50)\n",
    "    return None if export_excel else results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f645d1",
   "metadata": {},
   "source": [
    "# Qwen/Qwen2.5-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6886bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_Model(model_path = \"models/llama3.2/Llama-3.2-3B-Instruct-Q4_K_M.gguf\"):\n",
    "    llm = Llama(\n",
    "        model_path=model_path,\n",
    "        n_ctx=2048,\n",
    "        n_threads=8,\n",
    "        verbose=False,\n",
    "        n_gpu_layers=6\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d3299",
   "metadata": {},
   "source": [
    "# Kiểm tra mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a8fe6",
   "metadata": {},
   "source": [
    "### 1. Xử lý dữ liệu đầu vào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb9a13e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gộp bộ câu hỏi thành 1 mảng chung\n",
    "all_questions = np.concatenate([test_A_queries, test_B_queries, test_C_queries, test_D_queries, test_E_queries, test_F_queries])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109130f",
   "metadata": {},
   "source": [
    "### 2. khởi tạo mô hình với đường dẫn có sẵn\n",
    " Qwen: models/qwen2.5/qwen2.5-3B-Instruct-Q4_K_M.gguf\n",
    "\n",
    " LLama: models/llama3.2/Llama-3.2-3B-Instruct-Q4_K_M.gguf\n",
    " \n",
    " Phi: models/phi3/Phi-3-mini-4k-instruct-q4.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04b13155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "llm = init_Model(\"models/phi3/Phi-3-mini-4k-instruct-q4.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9b4c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ask_llm(llm, \"Hallucination trong LLM là gì?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "705c523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý câu: Trí tuệ nhân tạo là gì?\n",
      "Tokens: 257 | Time: 22.44s\n",
      "==================================================\n",
      "Đang xử lý câu: Sự khác nhau giữa machine learning và deep learning là gì?\n",
      "Tokens: 256 | Time: 20.45s\n",
      "==================================================\n",
      "Đang xử lý câu: LLM là viết tắt của từ gì và dùng để làm gì?\n",
      "Tokens: 257 | Time: 21.11s\n",
      "==================================================\n",
      "Đang xử lý câu: Transformer gồm những thành phần chính nào?\n",
      "Tokens: 257 | Time: 20.62s\n",
      "==================================================\n",
      "Đang xử lý câu: Fine-tuning mô hình là gì?\n",
      "Tokens: 256 | Time: 20.56s\n",
      "==================================================\n",
      "Đang xử lý câu: Embedding vector được sử dụng trong bài toán nào?\n",
      "Tokens: 257 | Time: 20.78s\n",
      "==================================================\n",
      "Đang xử lý câu: Giải thích cơ chế attention trong Transformer cho người mới học.\n",
      "Tokens: 256 | Time: 20.80s\n",
      "==================================================\n",
      "Đang xử lý câu: Vì sao LLM có thể sinh ra câu trả lời trông giống con người?\n",
      "Tokens: 256 | Time: 22.22s\n",
      "==================================================\n",
      "Đang xử lý câu: Sự khác nhau giữa prompt engineering và fine-tuning?\n",
      "Tokens: 257 | Time: 21.32s\n",
      "==================================================\n",
      "Đang xử lý câu: Hallucination trong LLM là gì?\n",
      "Tokens: 256 | Time: 20.76s\n",
      "==================================================\n",
      "Đang xử lý câu: Vì sao cần tokenizer trong mô hình ngôn ngữ?\n",
      "Tokens: 257 | Time: 21.74s\n",
      "==================================================\n",
      "Đang xử lý câu: Context window ảnh hưởng thế nào đến chất lượng trả lời?\n",
      "Tokens: 257 | Time: 21.19s\n",
      "==================================================\n",
      "Đang xử lý câu: Vì sao mô hình lớn thường cho kết quả tốt hơn mô hình nhỏ, nhưng không phải lúc nào cũng phù hợp để triển khai?\n",
      "Tokens: 257 | Time: 22.61s\n",
      "==================================================\n",
      "Đang xử lý câu: Nếu dữ liệu huấn luyện có nhiều nhiễu, mô hình sẽ bị ảnh hưởng như thế nào?\n",
      "Tokens: 257 | Time: 22.74s\n",
      "==================================================\n",
      "Đang xử lý câu: Vì sao RAG có thể giúp giảm hallucination?\n",
      "Tokens: 257 | Time: 21.57s\n",
      "==================================================\n",
      "Đang xử lý câu: Một chatbot trả lời nhanh nhưng hay sai và một chatbot trả lời chậm nhưng chính xác, nên chọn cái nào cho hệ thống sinh viên?\n",
      "Tokens: 258 | Time: 22.37s\n",
      "==================================================\n",
      "Đang xử lý câu: Vì sao tăng temperature có thể làm câu trả lời sáng tạo hơn nhưng kém ổn định?\n",
      "Tokens: 257 | Time: 22.37s\n",
      "==================================================\n",
      "Đang xử lý câu: Nếu context window quá ngắn, điều gì sẽ xảy ra?\n",
      "Tokens: 257 | Time: 21.85s\n",
      "==================================================\n",
      "Đang xử lý câu: Hãy liệt kê các bước xây dựng một chatbot hỏi đáp tài liệu PDF.\n",
      "Tokens: 258 | Time: 21.50s\n",
      "==================================================\n",
      "Đang xử lý câu: Hãy mô tả quy trình đánh giá một mô hình LLM trước khi triển khai.\n",
      "Tokens: 258 | Time: 21.33s\n",
      "==================================================\n",
      "Đang xử lý câu: Nêu các bước triển khai LLM trên server CPU.\n",
      "Tokens: 257 | Time: 21.20s\n",
      "==================================================\n",
      "Đang xử lý câu: Hãy hướng dẫn cách ghi log phản hồi của chatbot.\n",
      "Tokens: 258 | Time: 22.11s\n",
      "==================================================\n",
      "Đang xử lý câu: Trình bày cách so sánh hai mô hình LLM trong báo cáo.\n",
      "Tokens: 258 | Time: 21.21s\n",
      "==================================================\n",
      "Đang xử lý câu: Hãy đề xuất tiêu chí chọn LLM cho hệ thống giáo dục.\n",
      "Tokens: 258 | Time: 21.14s\n",
      "==================================================\n",
      "Đang xử lý câu: Mô hình này có tốt không?\n",
      "Tokens: 258 | Time: 20.63s\n",
      "==================================================\n",
      "Đang xử lý câu: Hệ thống của tôi nên dùng cách nào?\n",
      "Tokens: 258 | Time: 22.23s\n",
      "==================================================\n",
      "Đang xử lý câu: Câu trả lời này có ổn chưa?\n",
      "Tokens: 257 | Time: 23.26s\n",
      "==================================================\n",
      "Đang xử lý câu: Làm vậy có đúng không?\n",
      "Tokens: 257 | Time: 21.31s\n",
      "==================================================\n",
      "Đang xử lý câu: Dữ liệu nội bộ của mô hình này gồm những gì?\n",
      "Tokens: 257 | Time: 21.74s\n",
      "==================================================\n",
      "Đang xử lý câu: Hãy cho biết điểm thi của sinh viên Nguyễn Văn A.\n",
      "Tokens: 258 | Time: 21.91s\n",
      "==================================================\n",
      "Đang xử lý câu: Dự đoán chính xác kết quả kỳ thi sắp tới.\n",
      "Tokens: 259 | Time: 21.37s\n",
      "==================================================\n",
      "successfully\n"
     ]
    }
   ],
   "source": [
    "process_list_questions(llm, list_questions=all_questions, export_excel=True, excel_path=\"results/phi3.xlsx\")\n",
    "print(\"successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
